<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction</h1>

                        <!-- 作者列表部分 -->
            <!-- 作者列表部分 -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">Zhiyi Hou<sup>1,2,3,*</sup>,</span>
              <span class="author-block">Enhui Ma<sup>1,3,*</sup>,</span>
              <span class="author-block">Fang Li<sup>2,*</sup>,</span>
              <span class="author-block">Zhiyi Lai<sup>2</sup>,</span>
              <span class="author-block">Kalok Ho<sup>2</sup>,</span>
              <span class="author-block">Zhanqian Wu<sup>2</sup>,</span>
              <span class="author-block">Lijun Zhou<sup>2</sup>,</span>
              <span class="author-block">Long Chen<sup>2</sup>,</span>
              <span class="author-block">Chitian Sun<sup>2</sup>,</span>
              <span class="author-block">Haiyang Sun<sup>2,†</sup>,</span>
              <span class="author-block">Bing Wang<sup>2</sup>,</span>
              <span class="author-block">Guang Chen<sup>2</sup>,</span>
              <span class="author-block">Hangjun Ye<sup>2</sup>,</span>
              <span class="author-block">Kaicheng Yu<sup>1,✉</sup></span>
            </div>
            <div class="is-size-6 publication-affiliations">
              <sup>1</sup>Westlake University, <sup>2</sup>Xiaomi EV, <sup>3</sup>Zhejiang University<br>
              <span class="eql-cntrb"><small><sup>*</sup>Equal Contribution</small></span>
              <span><small>†Project Leader</small></span>
              <span><small>✉Corresponding author</small></span>
            </div>
                              <div class="column has-text-centered">
                                <div class="publication-links">
                                     <!-- Arxiv PDF link -->
                                  <!-- <span class="link-block">
                                    <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                      <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                  </a>
                                </span> -->
            
                                <!-- Supplementary PDF link -->
                                <!-- <span class="link-block">
                                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fas fa-file-pdf"></i>
                                  </span>
                                  <span>Supplementary</span>
                                </a>
                              </span> -->
            
                                <!-- Github link -->
                                <!-- <span class="link-block">
                                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="fab fa-github"></i>
                                  </span>
                                  <span>Code</span>
                                </a>
                              </span> -->
            
                                <!-- ArXiv abstract Link -->
                                <!-- <span class="link-block">
                                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                                  class="external-link button is-normal is-rounded is-dark">
                                  <span class="icon">
                                    <i class="ai ai-arxiv"></i>
                                  </span>
                                  <span>arXiv</span>
                                </a>
                              </span> -->
                        </div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </section>


<!-- Teaser 图片 -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- 添加标题到图片上方 -->
      <h2 class="title is-3 has-text-centered" style="margin-bottom: 2rem;">Method Overview</h2>
      
      <!-- 图片容器添加圆角和阴影 -->
      <div class="has-text-centered" style="border-radius: 8px; overflow: hidden; box-shadow: 0 4px 20px rgba(0,0,0,0.15);">
        <img 
          src="static/images/teaser_00.jpg"
          alt="Method Overview Banner" 
          class="is-fullwidth"
          style="max-height: 500px; object-fit: cover;">
      </div>
      
      <!-- 添加图片描述（可选） -->
      <p class="has-text-centered" style="margin-top: 1.5rem; color: #666; font-style: italic;">
        We enhance vision-language models (VLMs) for motion risk prediction by synthesizing high-risk motion data via a Bird’s-Eye View (BEV)-based motion simulation and introducing a VLM-agnostic framework with a projection-based visual prompting scheme to address the modality gap.
      </p>
    </div>
  </div>
</section>
<!-- End teaser 图片 -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomous driving has seen significant progress, driven by extensive real-world data. However, in long-tail scenarios, accurately predicting the safety of the ego vehicle’s future motion remains a major challenge due to uncertainties in dynamic environments and limitations in data coverage. In this work, we aim to explore whether it is possible to enhance the motion risk prediction capabilities of Vision-Language Models (VLM) by synthesizing high-risk motion data. Specifically, we introduce a Bird’s-Eye View (BEV) based motion simulation method to model risks from three aspects: the ego-vehicle, other vehicles, and the environment. This allows us to synthesize plug-and-play, high-risk motion data suitable for VLM training, which we call DriveMRP-10K. Furthermore, we design a VLM-agnostic motion risk estimation framework, named DriveMRP-Agent. This framework incorporates a novel information injection strategy for global context, ego-vehicle perspective, and trajectory projection, enabling VLMs to effectively reason about the spatial relationships between motion waypoints and the environment. Extensive experiments demonstrate that by fine-tuning with DriveMRP-10K, our DriveMRP-Agent framework can significantly improve the motion risk prediction performance of multiple VLM baselines, with the accident recognition accuracy soaring from 27.13% to 88.03%. Moreover, when tested via zero-shot evaluation on an in-house real-world high-risk motion dataset, DriveMRP-Agent achieves a significant performance leap, boosting the accuracy from base_model’s 29.42% to 68.50%, which showcases the strong generalization capabilities of our method in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method 模块 -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        
        <!-- DriveMRP-10K 部分 -->
        <div class="method-section" id="drivemrp-10k">
          <h3 class="title is-4 has-text-left">1 DriveMRP-10K</h3>
          <div class="method-image-container" style="border-radius: 8px; overflow: hidden; box-shadow: 0 4px 15px rgba(0,0,0,0.1); margin-bottom: 1.5rem;">
            <img 
              src="static/images/DriveMRP-Data_00.jpg"
              alt="DriveMRP-10K Dataset Generation Pipeline" 
              class="is-fullwidth"
              style="max-height: 350px; object-fit: cover;">
          </div>
          <div class="content has-text-justified">
            <p>
              A synthetic dataset of high-risk driving motions built from nuPlan. 
              Uses BEV-based simulation to model risks from ego-vehicle, other agents, and environment. 
              Includes trajectory generation, human-in-the-loop labeling, and GPT-4o captions, yielding 10K multimodal samples for VLM training.
            </p>
          </div>
        </div>
        
        <!-- DriveMRP-Agent 部分 -->
        <div class="method-section" id="drivemrp-agent">
          <h3 class="title is-4 has-text-left">2 DriveMRP-Agent</h3>
          <div class="method-image-container" style="border-radius: 8px; overflow: hidden; box-shadow: 0 4px 15px rgba(0,0,0,0.1); margin-bottom: 1.5rem;">
            <img 
              src="static/images/drivemrp-agent_00.jpg"
              alt="DriveMRP-Agent Framework Architecture" 
              class="is-fullwidth"
              style="max-height: 350px; object-fit: cover;">
          </div>
          <div class="content has-text-justified">
            <p>
              A VLM-agnostic framework based on Qwen2.5VL-7B. 
              Employs projection-based visual prompting to bridge numerical coordinates and images. 
              Combines BEV and front-view contexts to enable chain-of-thought reasoning for motion risk prediction.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Method 模块 -->

<!-- 视频展示区 -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">
      Risk scenarios in DriveMRP - 10K</h2>
    <div class="columns is-multiline is-centered" style="margin-top: 2rem;">
      
      <!-- 第一个视频 -->
      <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile">
        <div class="video-card">
          <video 
            src="static/videos/acc-1.mp4" 
            alt="Video 1" 
            controls 
            muted 
            loop 
            autoplay
            class="is-fullwidth" 
            style="height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
          </video>
          <h3 class="subtitle is-6 has-text-centered" style="margin-top: 0.5rem;">
            Emergency acceleration scenario
          </h3>
        </div>
      </div>

      <!-- 第二个视频 -->
      <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile">
        <div class="video-card">
          <video 
            src="static/videos/dec-1.mp4" 
            alt="Video 2" 
            controls 
            muted 
            loop 
            autoplay
            class="is-fullwidth" 
            style="height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
          </video>
          <h3 class="subtitle is-6 has-text-centered" style="margin-top: 0.5rem;">
            Emergency braking scenario
          </h3>
        </div>
      </div>

      <!-- 第三个视频 -->
      <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile">
        <div class="video-card">
          <video 
            src="static/videos/col.mp4" 
            alt="Video 3" 
            controls 
            muted 
            loop 
            autoplay
            class="is-fullwidth" 
            style="height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
          </video>
          <h3 class="subtitle is-6 has-text-centered" style="margin-top: 0.5rem;">
            Collision scenario
          </h3>
        </div>
      </div>

      <!-- 第四个视频 -->
      <div class="column is-one-quarter-desktop is-half-tablet is-full-mobile">
        <div class="video-card">
          <video 
            src="static/videos/change_lane.mp4" 
            alt="Video 4" 
            controls 
            muted 
            loop 
            autoplay
            class="is-fullwidth" 
            style="height: 200px; object-fit: cover; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);">
          </video>
          <h3 class="subtitle is-6 has-text-centered" style="margin-top: 0.5rem;">
            Illegal lane change scenario
          </h3>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End 视频展示区 -->


<!-- DriveMRP-Agent推理结果展示区 -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">DriveMRP-Agent Inference Results</h2>
    
    <!-- 案例1：非法变道风险 -->
    <div class="result-card" style="margin: 3rem auto; width: 80%; border-radius: 8px; box-shadow: 0 6px 24px rgba(0,0,0,0.15);">
      <a href="static/images/case4_00.jpg" target="_blank">
        <img 
          src="static/images/case4_00.jpg" 
          alt="Illegal Lane Change Risk Case" 
          class="is-fullwidth" 
          style="width: 100%; object-fit: cover; border-radius: 8px;">
      </a>
      <div class="content has-text-left" style="padding: 1.5rem;">
        <h3 class="title is-6">Case 1: Illegal Lane Change Risk</h3>
        <p>
          Comparison of risk predictions across models for an illegal lane change scenario. 
          DriveMRP accurately identifies the risk (ground truth: illegal lane change), 
          while baseline models (Qwen2.5VL-7B, Intern2.5VL-8B) misclassify it as "no risk".
        </p>
      </div>
    </div>

    <!-- 案例2：异常减速风险 -->
    <div class="result-card" style="margin: 3rem auto; width: 80%; border-radius: 8px; box-shadow: 0 6px 24px rgba(0,0,0,0.15);">
      <a href="static/images/case2_00.jpg" target="_blank">
        <img 
          src="static/images/case2_00.jpg" 
          alt="Abnormal Deceleration Risk Case" 
          class="is-fullwidth" 
          style="width: 100%; object-fit: cover; border-radius: 8px;">
      </a>
      <div class="content has-text-left" style="padding: 1.5rem;">
        <h3 class="title is-6">Case 2: Abnormal Deceleration Risk</h3>
        <p>
          Model performance on an abnormal deceleration scenario. 
          DriveMRP detects the risk from trajectory color changes (ground truth: abnormal deceleration), 
          while baselines fail to recognize the sudden speed drop.
        </p>
      </div>
    </div>

    <!-- 案例3：碰撞风险 -->
    <div class="result-card" style="margin: 3rem auto; width: 80%; border-radius: 8px; box-shadow: 0 6px 24px rgba(0,0,0,0.15);">
      <a href="static/images/case3_00.jpg" target="_blank">
        <img 
          src="static/images/case3_00.jpg" 
          alt="Collision Risk Case" 
          class="is-fullwidth" 
          style="width: 100%; object-fit: cover; border-radius: 8px;">
      </a>
      <div class="content has-text-left" style="padding: 1.5rem;">
        <h3 class="title is-6">Case 3: Collision Risk</h3>
        <p>
          Collision risk evaluation at an intersection. 
          DriveMRP identifies the threat from the ego-vehicle’s trajectory proximity to the black car (ground truth: collision risk), 
          while baselines misclassify it as "no risk".
        </p>
      </div>
    </div>

  </div>
</section>
<!-- End 推理结果展示区 -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<!-- BibTeX 引用部分 -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{hou2025drivemrp,
  title     = {DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction},
  author    = {Hou, Zhiyi and Ma, Enhui and Li, Fang and Lai, Zhiyi and Ho, Kalok and Wu, Zhanqian and Zhou, Lijun and Chen, Long and Sun, Chitian and Sun, Haiyang and Wang, Bing and Chen, Guang and Ye, Hangjun and Yu, Kaicheng},
  year      = {2025}
}</code></pre>
  </div>
</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
